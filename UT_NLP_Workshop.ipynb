{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UT-NLP-Workshop.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EDB6cvUe3gVp"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMivgOqqgElm",
        "colab_type": "text"
      },
      "source": [
        "# University of Twente - Natural Language Processing - Workshop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDB6cvUe3gVp",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "In this workshop we are going to generate texts using various Neural Language Models. The goal of the workshop is to give you some experience with these models and allow you to tweak their behavior to see what impact your changes have.\n",
        "\n",
        "### Notes\n",
        "- The sessions in Google Colab are not persistent and will only run for up to 12 hours. If you want to keep your progress, please do so by connecting it with Google Drive.\n",
        "- GPU (and TPU) support is available. You can enable it by going to 'Runtime' -> 'Change Runtime Type' and selecting a GPU. This will reset the runtime, meaning that you may need to re-run the code cells.\n",
        "- The internet contains many datasets which you can use in this workshop. Examples include the FastAI datasets, Keras, and Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3ZCP1Q73lWz",
        "colab_type": "text"
      },
      "source": [
        "# Basic LSTM in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIvZt3Kh380Q",
        "colab_type": "text"
      },
      "source": [
        "In this section we are going to use LSTMs to generate texts using Nietzsche's writings as input. We follow this [example](https://keras.io/examples/lstm_text_generation/) from the Keras team."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM4YXV25gMkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import io\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzlPrLROG-_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if we are using the GPU. You should see: '/device:GPU:0'\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuMQ8n0Q-gf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Settings\n",
        "dataset = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt'\n",
        "keep_fraction = 0.3\n",
        "\n",
        "maxlen = 40   # maximum sequence size (in characters)\n",
        "step = 3      # step size to create sequences\n",
        "\n",
        "lstm_learning_rate = 0.01\n",
        "lstm_activation = 'softmax'\n",
        "\n",
        "batch_size = 128\n",
        "num_epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xe6JYaSgQX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load corpus - Nietzsche\n",
        "\n",
        "# Download the dataset, read the text and lowercase it.\n",
        "path = get_file(\n",
        "    'dataset.txt',\n",
        "    origin=dataset)\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "# The dataset contains over 90k words. Which is rather small, but will still take too long to train during this workshop.\n",
        "# Lets reduce the size of the data set.\n",
        "# Feel free to remove this.\n",
        "number_of_characters_to_keep = int(len(text) * keep_fraction)\n",
        "text = text[:number_of_characters_to_keep]\n",
        "\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('Number of unique characters:', len(chars))\n",
        "\n",
        "# We assign an integer value to each unique character\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# The mapping\n",
        "print('Character indices:', char_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGvQDly0_DQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create snippets of the text by sliding over it.\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "    \n",
        "print('Number of sequences created:', len(sentences))\n",
        "\n",
        "print('Examples of sequences:', sentences[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so_zfZRuAQD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create vectors of the input data\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "    \n",
        "print(f'We\\'ve created {len(sentences)} sequences, of length {maxlen}, with {len(chars)} unique characters.')\n",
        "# Now we've created a boolean representation of that.\n",
        "print('X dimensions:', x.shape)\n",
        "print('Y dimensions:', y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5izpOW-0E5Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a simple model with one LSTM of 128 units\n",
        "# Feel free to add more or tweak the settings!\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "lstm_model.add(Dense(len(chars), activation=lstm_activation))\n",
        "\n",
        "lstm_optimizer = RMSprop(lstm_learning_rate)\n",
        "lstm_model.compile(loss='categorical_crossentropy', optimizer=lstm_optimizer)\n",
        "\n",
        "# Note, we are not training the model yet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgjyyQC7Ftzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper functions\n",
        "def sample(preds, diversity=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / diversity\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = lstm_model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytKONhedF6qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model. This will take some time.\n",
        "model.fit(x, y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stl5eEOLI6Ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Yes! We've created a model and are now able to annoy Reddit, Facebook, and so on, with our fab texts!\n",
        "\n",
        "def generate_random_text(length=120):\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    diversity = 1.0\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    for i in range(length):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        generated += next_char\n",
        "    return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCA3qJ2aK-n-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_random_text(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5EN8h8MektZ",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "Now try changing the model and dataset. Can you improve the results?\n",
        "\n",
        "How about changing the data from character to word based?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsJr0MD7evE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Insert modified code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDl18pCX42pS",
        "colab_type": "text"
      },
      "source": [
        "# CNN in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ggtAMxIbBW",
        "colab_type": "text"
      },
      "source": [
        "This time we'll create a CNN-based classifier using the pre-trained [GloVe](http://nlp.stanford.edu/projects/glove/) word embeddings. This example is based on [this](https://github.com/keras-team/keras/blob/master/examples/pretrained_word_embeddings.py) script from the Keras team."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "482uSoOn461B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWcxRGYchUal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Settings\n",
        "glove_embeddings_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "newsgroup_data_url = 'http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz'\n",
        "\n",
        "base_dir = Path('.')\n",
        "glove_dir = base_dir / 'glove.6B'\n",
        "text_data_dir = base_dir / '20_newsgroup'\n",
        "max_sequence_length = 1000\n",
        "max_num_words = 20000\n",
        "embedding_dim = 100\n",
        "validation_split = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOQDUnGoiGTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and extract data\n",
        "glove_res = requests.get(glove_embeddings_url)\n",
        "with zipfile.ZipFile(io.BytesIO(glove_res.content)) as zf:\n",
        "  zf.extractall(glove_dir)\n",
        "\n",
        "news_res = requests.get(newsgroup_data_url)\n",
        "with tarfile.open(io.BytesIO(news_res.content), 'r:gz') as tf:\n",
        "  tf.extractall(base_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjnfNDNIiGtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Index word vectors\n",
        "embeddings_index = {}\n",
        "with open(glove_dir / 'glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs\n",
        "        \n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj-xxQoKiHCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process text data\n",
        "texts = []  # list of text samples\n",
        "labels_index = {}  # dictionary mapping label name to numeric id\n",
        "labels = []  # list of label ids\n",
        "for name in sorted(os.listdir(text_data_dir)):\n",
        "    path = os.path.join(text_data_dir, name)\n",
        "    if os.path.isdir(path):\n",
        "        label_id = len(labels_index)\n",
        "        labels_index[name] = label_id\n",
        "        for fname in sorted(os.listdir(path)):\n",
        "            if fname.isdigit():\n",
        "                fpath = os.path.join(path, fname)\n",
        "                args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n",
        "                with open(fpath, **args) as f:\n",
        "                    t = f.read()\n",
        "                    i = t.find('\\n\\n')  # skip header\n",
        "                    if 0 < i:\n",
        "                        t = t[i:]\n",
        "                    texts.append(t)\n",
        "                labels.append(label_id)\n",
        "\n",
        "print('Found %s texts.' % len(texts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1eLux-niHMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(num_words=max_num_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH36BqAKiHXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find unique words\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE_9vC9wlCe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create data and label tensors\n",
        "data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-rj2MOQlCp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split in train and test\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "num_validation_samples = int(validation_split * data.shape[0])\n",
        "\n",
        "x_train = data[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = data[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D19C9AvlCzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare embedding matrix\n",
        "num_words = min(max_num_words, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_num_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y7ZqyQHlC9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the embedding layer\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQLjhii_iHhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "preds = Dense(len(labels_index), activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASbglye2lpYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v19n3zjLlpkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the model for classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oojHgJywlpuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How could you use the embeddings and the CNN to generate texts?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuZ9auWYlp4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1hM_rbA47hP",
        "colab_type": "text"
      },
      "source": [
        "# AWD-LSTM in fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwSWJG42MpbR",
        "colab_type": "text"
      },
      "source": [
        "This time we use the AWD-LSTM in fastai to generate movie reviews.\n",
        "\n",
        "The complete example can be found here: './fastai-nlp-course/5-nn-imdb.ipynb'"
      ]
    }
  ]
}